# ğŸ“‘ Multi-Document RAG Chatbot

A **context-aware Multi-Document Retrieval-Augmented Generation (RAG) chatbot** that allows users to interact with multiple PDF documents through natural language queries. The chatbot retains **conversation memory**, enabling meaningful follow-up questions and coherent multi-turn conversations.

---

## Features

- Read and process multiple PDF documents  
- Extract and chunk text into smaller, meaningful segments  
- Generate vector embeddings using HuggingFace models  
- Store embeddings persistently in ChromaDB  
- Perform semantic search for relevant document context  
- Maintain conversational memory across user interactions  
- Generate accurate, context-aware responses using **LLaMA 3.3 70B** via Groq  
- Interactive web interface built with Streamlit  

---

## ğŸ§  How It Works

**Pipeline Overview:**
```
PDF Documents
â†“
Text Extraction
â†“
Text Chunking
â†“
Vector Embeddings (HuggingFace)
â†“
ChromaDB (Vector Store)
â†“
Semantic Retrieval
â†“
LLaMA 3.3 70B (Groq)
â†“
Conversational Response
```


---

## ğŸ› ï¸ Tech Stack

- **LangChain** â€“ RAG pipeline & conversational retrieval  
- **ChromaDB** â€“ Vector database for semantic search  
- **HuggingFace Embeddings** â€“ Text vectorization  
- **Groq (LLaMA 3.3 70B)** â€“ Large Language Model inference  
- **Streamlit** â€“ User interface  
- **Python** â€“ Core implementation  

---

## ğŸ“‚ Project Structure
```
Multi_document_RAG_chatbot/ 
â”‚
â”œâ”€â”€ main.py # Streamlit application
â”œâ”€â”€ vectorize_documents.py # PDF processing & embedding generation 
â”œâ”€â”€ vector_db_dir/ # Persistent ChromaDB storage 
â”œâ”€â”€ config.json # API key configuration (ignored in Git) 
â”œâ”€â”€ config.example.json # Example configuration file 
â”œâ”€â”€ requirements.txt # Project dependencies 
â”œâ”€â”€ README.md # Project documentation 
â””â”€â”€ .gitignore # Ignored files

```
---

## âš™ï¸ Setup & Installation

### 1ï¸âƒ£ Clone the repository
```bash
git clone https://github.com/your-username/multi-document-rag-chatbot.git
cd multi-document-rag-chatbot
```
### 2ï¸âƒ£ Create & Activate Virtual Environment
```bash
python -m venv .venv
.venv\Scripts\activate
```
### 3ï¸âƒ£ Install Dependencies
```bash
pip install -r requirements.txt
```
### 4ï¸âƒ£ Configure API Key
```bash
Rename config.example.json to config.json and add your Groq API key:

{
  "GROQ_API_KEY": "your_groq_api_key_here"
}
```


### â–¶ï¸ Running the Application

### Step 1ï¸âƒ£: Add PDF Documents
```
Place your PDF files inside the data/ directory.
```
### Step 2ï¸âƒ£: Vectorize Documents

Run the document ingestion and embedding pipeline:
```
vectorize_documents.py
```
This step:
```
Loads PDFs
â†“
Extracts and chunks text
â†“
Generates embeddings
â†“
Stores vectors in ChromaDB
```
### Step 3ï¸âƒ£: Launch the Chatbot
```
streamlit run main.py
```
Open the provided local URL in your browser to start chatting with your documents.



